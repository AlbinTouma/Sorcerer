{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def generate_identifiers():\n",
    "    def generate_primary_identifiers():\n",
    "        return {\n",
    "                'Name': ['_source.data.names.aliases', '_source.data.display_fields.title'], \n",
    "                'DoB': ['_source.data.births.age', '_source.data.births.max_date', '_source.data.births.min_date'], \n",
    "                'Location': ['_source.data.locations.location_type'],\n",
    "                'Assets': ['_source.assets.photo_count', '_source.assets.assets_types', '_source.assets.assets.external_urls']\n",
    "                }\n",
    "    def generate_secondary_identifiers():\n",
    "        return {\n",
    "            'Gender': ['_source.data.genders.gender'],\n",
    "            'Location': ['_source.data.locations.name', '_source.data.locations.locations_count'],\n",
    "            'Political Scope': ['_source.data.aml_types.aml_type', '_source.data.aml_types.end_date', '_source.data.aml_types.start_date', '_source.data.occupations.occupation']\n",
    "        }\n",
    "    \n",
    "    primary_identifiers = generate_primary_identifiers()\n",
    "    secondary_identifiers = generate_secondary_identifiers()\n",
    "   \n",
    "\n",
    "\n",
    "    return primary_identifiers, secondary_identifiers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rules for Complete, Insufficient, and Sufficient profiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def identify_non_null(value):\n",
    "    #If value is a list or array, iterate to see if there's notna value. Else, check if value is notna. \n",
    "    return int(any(pd.notna(val) for val in value)) if isinstance(value, (list, np.ndarray)) else int(pd.notna(value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def identify_notna(value):\n",
    "    #If value is a list or array, iterate to see if there's notna value. Else, check if value is notna. \n",
    "    return any(pd.notna(val) for val in value) if isinstance(value, (list, np.ndarray)) else pd.notna(value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def count_data_in_columns(row, selected_columns):\n",
    "    count = sum(1 if identify_notna(row[column]) else 0 for column in selected_columns)\n",
    "    name = True if any(pd.notna(val) for val in row['_source.data.names.name']) else False\n",
    "    #Might need to add condition that checks if there's a value for at least one in political scope (True/False)\n",
    "    \n",
    "    return count, name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#df['Primary'] = df.apply(count_data_in_columns, selected_columns=primary_data_columns, axis=1)\n",
    "#df['Secondary'] = df.apply(count_data_in_columns, selected_columns=secondary_data_columns, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def completeness_classifier(row):\n",
    "    primary_value, secondary_value = row['Primary'], row['Secondary']\n",
    "    \n",
    "    status = 'complete' if primary_value[0] >=1 and secondary_value[0] >=2  else \\\n",
    "    'sufficient' if primary_value[0] >=1 and secondary_value[0] <1 or primary_value[0] <1 and secondary_value[0] >2 else \\\n",
    "    'insufficient' if primary_value[0] <1 else None\n",
    "    \n",
    "    return status "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def main():\n",
    "    df = pd.read_parquet('../../parquet/TheOfficialBoard.parquet')\n",
    "    \n",
    "    #Generate primary_identifiers and extract identifier columns as primary and secondary lists\n",
    "    primary_identifiers, secondary_identifiers = generate_identifiers()\n",
    "    primary_identifiers = [item for value_list in primary_identifiers.values() for item in value_list]\n",
    "    secondary_identifiers = [item for value_list in secondary_identifiers.values() for item in value_list]\n",
    "    \n",
    "    #Dynamically chose the primary and secondary columns that are in our dataframe\n",
    "    primary_data_columns = df.columns[df.columns.isin(primary_identifiers)].to_list()\n",
    "    secondary_data_columns =  df.columns[df.columns.isin(secondary_identifiers)].to_list()\n",
    "    \n",
    "    #Count non_nans and if df has a name by passing primary and secondary columns to count_data_in_columns function\n",
    "    df['Primary'] = df.apply(count_data_in_columns, selected_columns=primary_data_columns, axis=1)\n",
    "    df['Secondary'] = df.apply(count_data_in_columns, selected_columns=secondary_data_columns, axis=1)\n",
    "    df['Primary'] = [list(item) for item in df['Primary']] \n",
    "    df['Secondary'] = [list(item) for item in df['Secondary']] \n",
    "    \n",
    "   \n",
    "    #Apply the completness criteria to each row in the dataframe to identify profiles that are complete, sufficient, or insufficient\n",
    "    df['completeness'] = df.apply(completeness_classifier, axis=1)\n",
    "\n",
    "    df['Primary'] = df['Primary'].apply(str)\n",
    "    df['Secondary'] = df['Secondary'].apply(str)\n",
    "\n",
    "    df.to_parquet('../../parquet/TheOfficialBoard.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\AlbinTouma\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pyarrow\\pandas_compat.py:373: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if _pandas_api.is_sparse(col):\n"
     ]
    }
   ],
   "source": [
    "main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
