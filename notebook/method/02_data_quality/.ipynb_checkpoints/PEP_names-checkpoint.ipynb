{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://git.ivxs.uk/sanctions-and-watchlists/data-science/sanctions-data-audit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\AlbinTouma\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import altair as alt\n",
    "import json\n",
    "import nltk\n",
    "import re\n",
    "from typing import Optional, Iterable\n",
    "#Download common English stopwords ie the, at, etc\n",
    "nltk.download(\"stopwords\")\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Common words and phrases provided by the PEP team\n",
    "\"\"\"\n",
    "\n",
    "COMMON_ENGLISH_WORDS = [\n",
    "    \"the\",\n",
    "    \"of\",\n",
    "    \"and\",\n",
    "    \"to\",\n",
    "    \"in\",\n",
    "    \"for\",\n",
    "    \"is\",\n",
    "    \"on\",\n",
    "    \"that\",\n",
    "    \"by\",\n",
    "    \"this\",\n",
    "    \"with\",\n",
    "    \"you\",\n",
    "    \"it\",\n",
    "    \"not\",\n",
    "    \"or\",\n",
    "    \"be\",\n",
    "    \"are\",\n",
    "    \"from\",\n",
    "    \"at\",\n",
    "    \"as\",\n",
    "    \"your\",\n",
    "    \"all\",\n",
    "    \"have\",\n",
    "    \"new\",\n",
    "    \"an\",\n",
    "    \"was\",\n",
    "    \"we\",\n",
    "    \"home\",\n",
    "    \"us\",\n",
    "    \"about\",\n",
    "    \"if\",\n",
    "    \"has\",\n",
    "    \"search\",\n",
    "    \"free\",\n",
    "    \"but\",\n",
    "    \"our\",\n",
    "    \"one\",\n",
    "    \"other\",\n",
    "    \"information\",\n",
    "    \"time\",\n",
    "    \"they\",\n",
    "    \"site\",\n",
    "    \"up\",\n",
    "    \"what\",\n",
    "    \"which\",\n",
    "    \"their\",\n",
    "    \"news\",\n",
    "    \"out\",\n",
    "    \"use\",\n",
    "    \"any\",\n",
    "    \"there\",\n",
    "    \"only\",\n",
    "    \"so\",\n",
    "    \"his\",\n",
    "    \"when\",\n",
    "    \"contact\",\n",
    "    \"here\",\n",
    "    \"business\",\n",
    "    \"who\",\n",
    "    \"web\",\n",
    "    \"also\",\n",
    "    \"now\",\n",
    "    \"help\",\n",
    "    \"get\",\n",
    "    \"pm\",\n",
    "    \"view\",\n",
    "    \"online\",\n",
    "    \"first\",\n",
    "    \"am\",\n",
    "    \"been\",\n",
    "    \"would\",\n",
    "    \"how\",\n",
    "    \"were\",\n",
    "    \"me\",\n",
    "    \"services\",\n",
    "    \"some\",\n",
    "    \"these\",\n",
    "    \"click\",\n",
    "    \"its\",\n",
    "    \"like\",\n",
    "    \"service\",\n",
    "    \"than\",\n",
    "    \"find\",\n",
    "    \"date\",\n",
    "    \"back\",\n",
    "    \"top\",\n",
    "    \"people\",\n",
    "    \"had\",\n",
    "    \"list\",\n",
    "    \"name\",\n",
    "    \"just\",\n",
    "    \"over\",\n",
    "    \"state\",\n",
    "    \"year\",\n",
    "    \"into\",\n",
    "    \"email\",\n",
    "    \"two\",\n",
    "    \"health\",\n",
    "    \"world\",\n",
    "    \"re\",\n",
    "    \"next\",\n",
    "    \"used\",\n",
    "    \"go\",\n",
    "    \"work\",\n",
    "    \"last\",\n",
    "    \"most\",\n",
    "    \"products\",\n",
    "    \"music\",\n",
    "    \"buy\",\n",
    "    \"data\",\n",
    "    \"make\",\n",
    "    \"them\",\n",
    "    \"should\",\n",
    "    \"product\",\n",
    "    \"system\",\n",
    "    \"post\",\n",
    "    \"her\",\n",
    "    \"city\",\n",
    "    \"add\",\n",
    "    \"policy\",\n",
    "    \"number\",\n",
    "    \"such\",\n",
    "    \"please\",\n",
    "    \"available\",\n",
    "    \"copyright\",\n",
    "    \"support\",\n",
    "    \"message\",\n",
    "    \"after\",\n",
    "    \"best\",\n",
    "    \"software\",\n",
    "    \"then\",\n",
    "    \"jan\",\n",
    "    \"good\",\n",
    "    \"video\",\n",
    "    \"well\",\n",
    "    \"where\",\n",
    "    \"info\",\n",
    "    \"rights\",\n",
    "    \"public\",\n",
    "    \"books\",\n",
    "    \"high\",\n",
    "    \"school\",\n",
    "    \"through\",\n",
    "    \"each\",\n",
    "    \"links\",\n",
    "    \"she\",\n",
    "    \"review\",\n",
    "    \"years\",\n",
    "    \"order\",\n",
    "    \"very\",\n",
    "    \"privacy\",\n",
    "    \"book\",\n",
    "    \"items\",\n",
    "    \"company\",\n",
    "    \"read\",\n",
    "    \"group\",\n",
    "    \"sex\",\n",
    "    \"need\",\n",
    "    \"many\",\n",
    "    \"user\",\n",
    "    \"said\",\n",
    "    \"de\",\n",
    "    \"does\",\n",
    "    \"set\",\n",
    "    \"under\",\n",
    "    \"general\",\n",
    "    \"research\",\n",
    "    \"university\",\n",
    "    \"january\",\n",
    "    \"mail\",\n",
    "    \"full\",\n",
    "    \"map\",\n",
    "    \"reviews\",\n",
    "    \"program\",\n",
    "    \"life\",\n",
    "    \"know\",\n",
    "    \"games\",\n",
    "    \"way\",\n",
    "    \"days\",\n",
    "    \"management\",\n",
    "    \"part\",\n",
    "    \"could\",\n",
    "    \"great\",\n",
    "    \"united\",\n",
    "    \"hotel\",\n",
    "    \"real\",\n",
    "    \"item\",\n",
    "    \"international\",\n",
    "    \"center\",\n",
    "    \"ebay\",\n",
    "    \"must\",\n",
    "    \"store\",\n",
    "    \"travel\",\n",
    "    \"comments\",\n",
    "    \"made\",\n",
    "    \"development\",\n",
    "    \"report\",\n",
    "    \"off\",\n",
    "]\n",
    "\n",
    "\n",
    "DEFAULT_HONORIFICS = [\n",
    "    \"mr\",\n",
    "    \"mister\",\n",
    "    \"ms\",\n",
    "    \"miss\",\n",
    "    \"mrs\",\n",
    "    \"dr\",\n",
    "    \"doctor\",\n",
    "    \"phd\",\n",
    "    \"prof\",\n",
    "    \"professor\",\n",
    "    \"eng\",\n",
    "    \"sir\",\n",
    "    \"doc\",\n",
    "    \"judge\",\n",
    "    \"adv\",\n",
    "    \"advocate\",\n",
    "    \"king\",\n",
    "    \"queen\",\n",
    "    \"lord\",\n",
    "    \"lady\",\n",
    "    \"prince\",\n",
    "    \"princess\",\n",
    "    \"earl\",\n",
    "    \"baroness\",\n",
    "    \"baron\",\n",
    "    \"duke\",\n",
    "    \"duchess\",\n",
    "    \"marquess\",\n",
    "    \"marchioness\",\n",
    "    \"viscount\",\n",
    "    \"viscountess\",\n",
    "    \"honourable\",\n",
    "]\n",
    "\n",
    "INDONESIA_HONORIFICS = [\n",
    "    \"hj\",\n",
    "    \"h\",\n",
    "    \"ir\",\n",
    "    \"i.b\",\n",
    "    \"ida bagus\",\n",
    "    \"i.a\",\n",
    "    \"ida ayu\",\n",
    "    \"a.a\",\n",
    "    \"anak agung\",\n",
    "    \"cok\",\n",
    "    \"cokorda\",\n",
    "    \"gst\",\n",
    "    \"gusti\",\n",
    "    \"dw\",\n",
    "    \"dewa\",\n",
    "    \"ngkn\",\n",
    "    \"ngakan\",\n",
    "    \"dsk\",\n",
    "    \"desak\",\n",
    "    \"drs\",\n",
    "    \"se\",\n",
    "    \"mm\",\n",
    "    \"m.si\",\n",
    "    \"sh\",\n",
    "    \"s.ag.\",\n",
    "    \"kh\",\n",
    "    \"se\",\n",
    "    \"h.\",\n",
    "    \"dra. ir.\",\n",
    "    \"m.kes.\",\n",
    "    \"pdt.\",\n",
    "    \"s.sos.\",\n",
    "    \"s.h.\",\n",
    "    \"m.sp\",\n",
    "]\n",
    "\n",
    "ISRAEL_HONORIFICS = ['ד\"ר', \"adv.\", 'עו\"ד', \"פרופסור\", \"גב'\"]\n",
    "\n",
    "MALAYSIA_HONORIFICS = [\n",
    "    \"datuk\",\n",
    "    \"dato sri\",\n",
    "    \"dato seri\",\n",
    "    \"datuk seri\",\n",
    "    \"dato\",\n",
    "    \"datins\",\n",
    "    \"tun\",\n",
    "    \"tan seri\",\n",
    "    \"tan sri\",\n",
    "    \"encik\",\n",
    "    \"en\",\n",
    "    \"tuan\",\n",
    "    \"rn\",\n",
    "    \"tuan yang terutama\",\n",
    "    \"puan\",\n",
    "    \"madame\",\n",
    "    \"cik\",\n",
    "    \"tpr\",\n",
    "    \"registered town planner\",\n",
    "    \"tuan yang terutama\",\n",
    "    \"tyt\",\n",
    "    \"yang amat berhormat\",\n",
    "    \"yab\",\n",
    "    \"yang berhormat\",\n",
    "    \"yb\",\n",
    "    \"yang berhormat mulia\",\n",
    "    \"ybm\",\n",
    "    \"yang amat arif\",\n",
    "    \"yaa\",\n",
    "    \"yang arif\",\n",
    "    \"ya\",\n",
    "    \"yang amat berbahagia\",\n",
    "    \"yabhg\",\n",
    "    \"yang berbahagia\",\n",
    "    \"ybhg\",\n",
    "    \"Dato' Indera\",\n",
    "    \"Puan Sri\",\n",
    "    \"Seri\",\n",
    "    \"datin\",\n",
    "    \"Y.A.M.\",\n",
    "    \"Tengku\",\n",
    "    \"YBhg.\",\n",
    "    \"YM RAJA\",\n",
    "    \"YBM.\",\n",
    "    \"YH.\",\n",
    "    \"Y.Bhg.\",\n",
    "    \"Prof Madya\",\n",
    "    \"Emeritus\",\n",
    "    \"Setia\",\n",
    "    \"Pengiran\",\n",
    "    \"Dayang\",\n",
    "    \"Paduka\",\n",
    "    \"Awang\",\n",
    "    \"Yang Berhormat\"\n",
    "]\n",
    "\n",
    "NIGERIA_HONORIFICS = [\"alhaji\", \"alh\", \"barrister\", \"barr\", \"barr.\",\" FNSE\", \" SAN\", \" MNI\", \" MFR\"] \n",
    "                                    # not sure if we can keep (FNSE\", \" SAN\", \" MNI\", \" MFR)\n",
    "\n",
    "SOUTH_AFRICA_HONORICIS = [\"inkosi\"]\n",
    "\n",
    "THAILAND_HONORIFICS = [\n",
    "    # general honorifics\n",
    "    \"นาย\",  # mr\n",
    "    \"นาง\",  # mrs\n",
    "    \"หม่ sau ม.ล.\",  # ML\n",
    "    \"นายแพทย์\",  # doctor\n",
    "    \"นพ. sau พญ.\",  # dr./M.D.\n",
    "    \"ศรี\",  # Sri\n",
    "    \"คุณ\",  # Sir/Mister\n",
    "    \"นางสาว\",  # Ms.\n",
    "    \"ม.ร.ว.\",  # M.R.\n",
    "    \"นา\",  # Miss\n",
    "    \"ดร.\",  # Dr.\n",
    "    \"รศ.ดร.มั sau ศ.ดร.นพ. sau รศ.ดร.\",  # Prof. Dr.(sau Assoc. Prof. Dr.)\n",
    "    \"ศาตราจารย์ sau ศาสตราจ\",  # professor\n",
    "    \"นางสา\",  # Mrs.\n",
    "    \"ผศ.นพ.\",  # Assistant Professor\n",
    "    \"รองศาสตราจารย์ ดร.\",  # Associate Professor Dr.\n",
    "    \"ผู้ช่วยศาสตราจารย์ ดร.\",  # Assistant Professor Dr.\n",
    "    \"ศาสตราจารย์เกียรติคุณ\",  # Professor Emeritus\n",
    "    \"ศาสตราจารย์พิเศษ\",  # Special Professor\n",
    "    \"ทันตแพทย์\",  # dentist\n",
    "    \"น.ส.\",  # Miss\n",
    "    # ranks\n",
    "    \"พลเอก\",\n",
    "    \"พล.ท.\",  #  General\n",
    "    \"พลอากาศเอก\",\n",
    "    \"พลอากาศตรี\",  #  Air Chief Marshal\n",
    "    \"พลเรือเอก\",\n",
    "    \"พลเรือตรี\",  #  Admiral\n",
    "    \"ร้อยโท\",\n",
    "    \"พลโท\",\n",
    "    \"ว่าที่ร้อยตรี\",  #  Lieutenant, Acting Lieutenant\n",
    "    \"ร้อยตรี\",  #  Second Lieutenant\n",
    "    \"พันโท\",\n",
    "    \"พันตำรวจตรี\",  #  Lieutenant Colonel\n",
    "    \"พลตำรวจโท\",  #  Lieutenant General\n",
    "    \"พันตำรวจโท\",  #  Police lieutenant colonel\n",
    "    \"พ.ต.อ.\",  #  Pol. colonel\n",
    "    \"พลตำรวจเอก\",  #  Police General\n",
    "    \"พลตำรวจตรี\",  #  Police Major General\n",
    "    \"พันจ่าตรี\",  #  Major Sergeant(or Chief Petty Officer)\n",
    "    \"พลตรี\",\n",
    "    \"พล.ต.ต.\",  #  Major General\n",
    "    \"ร้อยตำรวจโทหญิง\",  #  Female Police Lieutenant\n",
    "    \"ร้อยเอก\",  #  Captain\n",
    "    \"พันจ่าเอก\",  #  Colonel/Major Sergeant\n",
    "    \"พันเอก\",\n",
    "    \"พันตำรวจเอก\",  #  Colonel\n",
    "    \"ว่าที่ร.ต.หญิง\",  #  Acting Lieutenant Female(or Acting Sub Lieutenant, translation is pretty bad)\n",
    "    # police ranks\n",
    "    \"พล.ต.อ.\",\n",
    "    \"พลตำรวจเอก\",  # POLICE  GENERAL  ( POL . GEN . )\n",
    "    \"พล.ต.ท.\",\n",
    "    \"พลตำรวจโท\",  # POLICE  LIEUTENANT  GENERAL  ( POL . LT . GEN . )\n",
    "    \"พล.ต.ต.\",\n",
    "    \"พลตำรวจตรี\",  # POLICE  MAJOR  GENERAL  ( POL . MAJ . GEN . )\n",
    "    \"พ.ต.อ.\",\n",
    "    \"พันตำรวจเอก\",  # POLICE  COLONEL  ( POL . COL . )\n",
    "    \"พ.ต.ท.\",\n",
    "    \"พันตำรวจโท\",  # POLICE  LIEUTENANT  COLONEL  ( POL . LT . COL . )\n",
    "    \"พ.ต.ต.\",\n",
    "    \"พันตำรวจตรี\",  # POLICE  MAJOR  ( POL . MAJ . )\n",
    "    \"ร.ต.อ.\",\n",
    "    \"ร้อยตำรวจเอก\",  # POLICE  CAPTAIN  ( POL . CAPT . )\n",
    "    \"ร.ต.ท.\",\n",
    "    \"ร้อยตำรวจโท\",  # POLICE  LIEUTENANT  ( POL . LT . )\n",
    "    \"ร.ต.ต.\",\n",
    "    \"ร้อยตำรวจตรี\",  # POLICE  SUB - LIEUTENANT  ( POL . SUB . LT . )\n",
    "    \"ด.ต.\",\n",
    "    \"ดาบตำรวจ\",  # POLICE  SENIOR  SERGEANT  MAJOR  ( POL . SEN . SGT . MAJ . )\n",
    "    \"จ.ส.ต.\",\n",
    "    \"จ่าสิบตำรวจ\",  # POLICE  SERGEANT  MAJOR  ( POL . SGT . MAJ . )\n",
    "    \"ส.ต.อ.\",\n",
    "    \"สิบตำรวจเอก\",  # POLICE  SERGEANT  ( POL . SGT . )\n",
    "    \"ส.ต.ท.\",\n",
    "    \"สิบตำรวจโท\",  # POLICE  CORPORAL  ( POL . CPL . )\n",
    "    \"ส.ต.ต.\",\n",
    "    \"สิบตำรวจตรี\",  # POLICE  LANCE  CORPORAL  ( POL . L / C . )\n",
    "    # common titles\n",
    "    \"ผู้บังคับหมู่\",  # SERVICEMAN\n",
    "    \"รองสารวัตร\",  # SQUAD  LEADER\n",
    "    \"สารวัุตร\",  # INSPECTOR\n",
    "    \"สารวัตรอำนวยการ\",  # STAFF  INSPECTOR\n",
    "    \"สารวัตรสืบสวนสอบสวน\",  # INVESTIGATION  INSPECTOR\n",
    "    \"สารวัตรปกครองป้องกัน\",  # ADMINISTRATION  INSPECTOR\n",
    "    \"สารวัตรจราจร\",  # TRAFFIC  INSPECTOR\n",
    "    \"รองผู้กำกับการ\",  # DEPUTY  SUPERINTENDENT\n",
    "    \"ผู้กำกับการ\",  # SUPERINTENDENT\n",
    "    \"รองผู้บังคับการ\",  # DEPUTY  COMMANDER\n",
    "    \"ผู้บังคับการ\",  # COMMANDER\n",
    "    \"จเรตำรวจ\",  # INSPECTOR - GENERAL\n",
    "    \"รองผู้บัญชาการ\",  # DEPUTY  COMMISSIONER\n",
    "    \"ผู้บัญชาการ\",  # COMMISSIONER\n",
    "    \"ผู้ช่วยผู้บัญชาการตำรวจแห่งชาติ\",  # ASSISTANT DIRECTOR-GENERAL OF THE ROYAL THAI POLICE  DEPARTMEMT\n",
    "    \"รองผู้บัญชาการตำรวจแห่งชาติ\",  # DEPUTY DIRECTOR-GENERAL OF THE ROYAL THAI POLICE DEPARTMEMT\n",
    "    \"ผู้บัญชาการตำรวจแห่งชาติ\",  # DIRECTOR-GENERAL OF THE ROYAL THAI POLICE DEPARTMEMT\n",
    "    # royal descendants\n",
    "    \"หม่อมหลวง\",  # Mom Luang\n",
    "    \"ณ อยุธยา\",  # Na Ayutthaya\n",
    "]\n",
    "\n",
    "VIETNAM_HONORIFICS = [\n",
    "    \"Đồng chí\",  # Comrades\n",
    "    \"Giáo sư\",\n",
    "    \"Viện sĩ\",  # Professor, Academy\n",
    "    \"Giáo sư\",  # Professor\n",
    "    \"GS.TS.\",  # Professor Dr.\n",
    "    \"Phó Giáo sư\",\n",
    "    \"Tiến sĩ\",  # Associate Professor Ph.D\n",
    "    \"PGS.TS.\",  #  Associate Professor Ph.D\n",
    "    \"TS.\",  # Dr / Ph.D\n",
    "    \"TS.NCVC.\",\n",
    "    \"Ths\",  # Master\n",
    "    \"ThS. Bs\",  # Master doctor\n",
    "    \"Ths.CVC.\",  # Master\n",
    "    \"ÔNG\",  # Mr.\n",
    "    \"BÀ\",  # Ms.\n",
    "    \"Đ\",\n",
    "    \"c\",  # Mr / Ms\n",
    "    \"Đại tướng\",  # General\n",
    "    \"Đại tá\",  # Colonel\n",
    "    \"Linh mục\",  # Priests\n",
    "    \"Thượng tướng\",  # Upper Minister\n",
    "    \"Hòa thượng\",  # Venerable\n",
    "    \"Giáo hữu\",  # believers\n",
    "]\n",
    "\n",
    "UNITED_KINGDOM_HONORIFICS = [\n",
    "    \"GBE\",\n",
    "    \"KBE\",\n",
    "    \"DBE\",\n",
    "    \"CBE\",\n",
    "    \"OBE\",\n",
    "    \"MBE\",\n",
    "    \"BEM\",\n",
    "    \"RVO\",\n",
    "    \"MEP\",\n",
    "    \"ministers of religion\",\n",
    "    \"KC\",\n",
    "    \"MP\",\n",
    "    \"QC\",\n",
    "    \"Rev\",    \n",
    "]\n",
    "\n",
    "MACEDONIA_HONORIFICS = [\n",
    "    \"Г-дин\",  # Mr\n",
    "    \"Г-ца\",  # Mrs\n",
    "]\n",
    "\n",
    "IRAN_HONORIFICS= [\n",
    "    \"سید\", #Syed/Seyed/Seyyed/Sayyed\n",
    "    \"آقای\", #Mr\n",
    "    \"خانم\", #Miss/Lady/Madam\n",
    "    \"جناب\", #Sir\n",
    "    \"دکترسید\", #this is somehow Sayyed combined with Dr\n",
    "    \"دکتر\", #the Doctor\n",
    "    \"مهندس\", #engineer\n",
    "    \"حجت الاسلام و المسلمین\", #honorific title meaning \"authority on Islam\" or \"proof of Islam\"\n",
    "    \"حجت‌الاسلام\", #honorific title meaning \"authority on Islam\" or \"proof of Islam\"\n",
    "    \"آیت‌الله\", #title of religious leader (Ayatollah is an honorific title for high ranking Twelver Shia clergy in Iran and Iraq)\n",
    "    \"مهندس سید\", #engineer seyed\n",
    "    \n",
    "    #ranks\n",
    "    \"سرتیپ پاسدار\", #brigadier general \n",
    "]\n",
    "\n",
    "CAMBODIA_HONORIFICS = [\n",
    "    \"បណ្ឌិត\",  # Doctor\n",
    "    \"លោកស្រីចៅក្រម\",  # Judge\n",
    "    \"ចៅក្រម\",  # Judge\n",
    "    \"ឯកឧត្តម\",  # His Excellency\n",
    "    \"ឯ.ឧ.\",  # E.g.(Exempli Gratia-abbreviation used to introduce examples in a sentence)\n",
    "    \"លោក\",  # Mr./Sir\n",
    "    \"លោកស្រី\",  # Mrs./Madam\n",
    "    \"លោកជំទាវ\",  # Lok Chumteav (title for high-ranking female officials or the wives of high-ranking ministers or government officials)\n",
    "]\n",
    "\n",
    "BANGLADESH_HONORIFICS = [\n",
    "    \"বেগম\",  # Begum\n",
    "    \"জনাব\",  # Mr\n",
    "    \"মিসেস\",  # Mrs\n",
    "    \"মিজ\",  # Miz\n",
    "    \"ডক্টর\",  # Dr\n",
    "    \"ডাঃ\",  # Dr\n",
    "    \"ড\",  # Dr\n",
    "    \"মাননীয়\",  # Hon (Honorable)\n",
    "    \"প্রকৌ\",  # Prof\n",
    "    \"এম.পি.\",  # M.P (Member of Parliament)\n",
    "    \"এমপি\",  # MP (Member of Parliament)\n",
    "    \"এনডিসি\",  # NDC (National Defense College/Course)\n",
    "    \"TPr\",  # Registered Town Planner (if found in name)\n",
    "]\n",
    "\n",
    "HONORIFICS_COUNTRY_MAPPING = {\n",
    "    \"General\": DEFAULT_HONORIFICS,\n",
    "    \"Indonesia\": INDONESIA_HONORIFICS,\n",
    "    \"Israel\": ISRAEL_HONORIFICS,\n",
    "    \"Malaysia\": MALAYSIA_HONORIFICS,\n",
    "    \"Nigeria\": NIGERIA_HONORIFICS,\n",
    "    \"South Africa\": SOUTH_AFRICA_HONORICIS,\n",
    "    \"Thailand\": THAILAND_HONORIFICS,\n",
    "    \"Vietnam\": VIETNAM_HONORIFICS,\n",
    "    \"Macedonia\": MACEDONIA_HONORIFICS,\n",
    "    \"Cambodia\": CAMBODIA_HONORIFICS,\n",
    "    \"Bangladesh\": BANGLADESH_HONORIFICS,\n",
    "}\n",
    "\n",
    "\n",
    "PEP_JOB_TITLES = {\n",
    "    \"ambassador\",\n",
    "    \"minister\", \n",
    "    \"charge\",\n",
    "    \"high commissioner\",\n",
    "    \"nuncio\",\n",
    "    \"head\",\n",
    "    \"mission\",\n",
    "    \"counsel\",\n",
    "    \"consul\",\n",
    "    \"secretar\",\n",
    "    \"attach\",\n",
    "    \"assistant\",\n",
    "    \"consular agent\",\n",
    "    \"honorary\",\n",
    "    \"officer\",\n",
    "    \"observer\",\n",
    "    \"representative\",\n",
    "    \"politician\",\n",
    "    \"member\",\n",
    "    \"membre\",\n",
    "    \"miembr\",\n",
    "    \"manager\",\n",
    "    \"president\",\n",
    "    \"chair\",\n",
    "    \"judge\",\n",
    "    \"chief\",\n",
    "    \"ceo\",\n",
    "    \"cfo\",\n",
    "    \"coo\",\n",
    "    \"cmo\",\n",
    "    \"cto\"\n",
    "    \"vp\",\n",
    "    \"deputy\",\n",
    "    \"cmd\",\n",
    "    \"director\",\n",
    "    \"board\",\n",
    "    \"vocal\",\n",
    "    \"secretar\",\n",
    "    \"jefe\",\n",
    "    \"jefa\",\n",
    "    \"commisioner\",\n",
    "    \"addl\",\n",
    "    \"dy.\",\n",
    "    \"hon\",\n",
    "    \"rector\",\n",
    "    \"officer\",\n",
    "    \"speaker\",\n",
    "    \"MEP\",\n",
    "    \"MP\",\n",
    "    \"Parliamentarian\",\n",
    "    \"市长\",  #mayor\n",
    "    \"副市长\", #vice-mayor\n",
    "    \"委常委\", # Member of the Standing Committee\n",
    "    \"部长\" # minister\n",
    "    \"书记\"  #secretary\n",
    "    \"Baskan\", # minister\n",
    "    \"başkan\",\n",
    "    \"Üyes\", #member\n",
    "    \"পরিচালক\",  # director\n",
    "    \"সচিব\",  # secretary\n",
    "    \"মন্ত্রী\", #minister\n",
    "}\n",
    "\n",
    "PEP_JOB_TITLES = {title.lower() for title in PEP_JOB_TITLES}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEFAULT_SEPARATORS = (\",\",\":\",\";\",\"\\n\",\"\\t\", \"|\")\n",
    "\n",
    "MULTILINGUAL_STOPWORDS = set()\n",
    "for lang in (\"english\", \"russian\", \"chinese\", \"spanish\", \"arabic\", \"french\"):\n",
    "    MULTILINGUAL_STOPWORDS.update(set(stopwords.words(lang)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_stopwords(text: str, stop_words: set = MULTILINGUAL_STOPWORDS) -> str:\n",
    "    \"\"\"Remove stopwords from a supplied text\n",
    "\n",
    "    Args:\n",
    "        text (str): text to be processed\n",
    "        stop_words (set, optional): _description_. Defaults to MULTILINGUAL_STOPWORDS.\n",
    "\n",
    "    Returns:\n",
    "        str: filtered text\n",
    "    \"\"\"\n",
    "    text_components = text.split()\n",
    "    return \" \".join([word for word in text_components if word.lower() not in stop_words])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_separators(text: str, separators: Optional[Iterable[str]] = None) -> int:\n",
    "    \"\"\"Count the occurrences of the separator characters in the input text.\n",
    "    \n",
    "    Args:\n",
    "        text (str): The input text to search for separator characters.\n",
    "        separators (Optional[Iterable[str]]): An iterable of separator characters to search for in the input text. Defaults to a tuple containing only the comma character (',') if no value is provided.\n",
    "        \n",
    "    Returns:\n",
    "        int: The number of times a separator character is found in the input text.\n",
    "        \n",
    "    Examples:\n",
    "        >>> count_separators(\"apple, banana, cherry\")\n",
    "        2\n",
    "        \n",
    "        >>> count_separators(\"apple; banana; cherry, pineapple\", separators=[\";\", \",\"])\n",
    "        3\n",
    "    \"\"\"\n",
    "    if separators is None:\n",
    "        separators = DEFAULT_SEPARATORS\n",
    "        \n",
    "    pattern = fr\"{'|'.join(map(re.escape, separators))}\"\n",
    "    characters = re.findall(pattern, text)\n",
    "    \n",
    "    return len(characters)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "name = 'Andre, Ryard, Mathew Jona'\n",
    "count_separators(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_repeat_components(text: str, strip_stopwords: bool = True) -> int:\n",
    "    \"\"\"\n",
    "    Count the number of repeated components in a given text.\n",
    "\n",
    "    Args:\n",
    "        text (str): The input text to be analyzed for repeated components.\n",
    "        strip_stopwords (bool): choose whether to strip out stopwords, defaults to True\n",
    "    Returns:\n",
    "        int: The number of repeated components in the input text.\n",
    "\n",
    "    Example:\n",
    "        >>> text = \"This is an example example text with repeated repeated components.\"\n",
    "        >>> count_repeat_components(text)\n",
    "        2\n",
    "    \"\"\"\n",
    "    if strip_stopwords:\n",
    "        text = filter_stopwords(text)\n",
    "    components = text.lower().split()\n",
    "    repeat_comps = len(components) - len(set(components))\n",
    "    return repeat_comps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Honorifics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n   for word in honorific_set:\\n        if word.lower() in text:\\n\\n            return True'"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def detect_honorifics(text: str) -> bool:\n",
    "    \"\"\"Compare a text string to our list of honorifics return True if any honorific appears\"\"\"\n",
    "    exclude_countries = {\"Indonesia\", \"Vietnam\"} # Don't use these honorifics for now - lots of false posititves from short titles\n",
    "    honorific_set = {word.lower() for k, v in HONORIFICS_COUNTRY_MAPPING.items() if k not in exclude_countries for word in v}\n",
    "    text = text.lower()\n",
    "\n",
    "    pattern = r'\\b(?:' + '|'.join(re.escape(word) for word in honorific_set) + r')\\b'\n",
    "    if re.search(pattern, text):\n",
    "        return True\n",
    "\n",
    "    return False\n",
    "\n",
    "'''\n",
    "   for word in honorific_set:\n",
    "        if word.lower() in text:\n",
    "\n",
    "            return True'''\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PEP_job_title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'    for word in PEP_JOB_TITLES:\\n        if word.lower() in text:\\n            return True\\n\\n    return False'"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def detect_pep_job_title(text: str) -> bool:\n",
    "    \"\"\"Compare a text string to our list of PEP job titles return True if any job title appears\"\"\"\n",
    "    text = text.lower()\n",
    "     # Use regular expression to match job titles as standalone words\n",
    "    for title in PEP_JOB_TITLES:\n",
    "        pattern = r'\\b' + re.escape(title) + r'\\b'\n",
    "        if re.search(pattern, text):\n",
    "            return True\n",
    "\n",
    "\n",
    "\n",
    "    return False\n",
    "    \n",
    "\n",
    "'''    for word in PEP_JOB_TITLES:\n",
    "        if word.lower() in text:\n",
    "            return True\n",
    "\n",
    "    return False'''\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Detect CJK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_cjk_chars(text: str) -> bool:\n",
    "    \"\"\"Check to see if cjk (Chinese, Japanese, Korean) chars are present in the text\"\"\"\n",
    "\n",
    "    if re.search(\"[\\uac00-\\ud7a3]\", text):\n",
    "        detection = True #ko\n",
    "    elif re.search(\"[\\u3040-\\u30ff]\", text):\n",
    "        detection = True #ja\n",
    "    elif re.search(\"[\\u4e00-\\u9FFF]\", text):\n",
    "        detection = True #zh\n",
    "    else:\n",
    "        detection = False\n",
    "\n",
    "    return detection\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PROCESS_PEP_NAME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_pep_name(name: str, separators: Optional[tuple[str]] = None) -> dict:\n",
    "    \"\"\"\n",
    "    Process a PEP's name and generate a dictionary of results.\n",
    "\n",
    "    Args:\n",
    "        name (str): The input name to be processed.\n",
    "        separators (Optional[tuple[str]], optional): A tuple of separator characters used to split name components.\n",
    "            If not provided, the default separators (\",\", \":\", \";\", \"/\", \"\\n\", \"\\t\") will be used. Default is None.\n",
    "\n",
    "    Returns:\n",
    "        dict: A dictionary containing the following keys:\n",
    "            - \"name\": The input name\n",
    "            - \"NAME_CHARS\": The number of characters in the input name\n",
    "            - \"NAME_COMPS\": The number of name components after splitting by separators\n",
    "            - \"SEP_COUNT\": The number of separator occurrences in the input name\n",
    "            - \"NUM_REPEAT_NAME_COMPS\": The number of repeated components in the input name\n",
    "    \"\"\"\n",
    "\n",
    "    if separators is None:\n",
    "        separators = DEFAULT_SEPARATORS\n",
    "    \n",
    "    results_dict = {\n",
    "        \"name\": name,\n",
    "        \"NAME_CHARS\": len(name),\n",
    "        \"NAME_COMPS\": len(name.split()),\n",
    "        \"SEP_COUNT\": count_separators(name, separators=separators),\n",
    "        \"NUM_REPEAT_NAME_COMPS\": count_repeat_components(name, strip_stopwords=False),\n",
    "        \"HONORIFIC_PRESENT\": detect_honorifics(name),\n",
    "        \"JOB_TITLE_PRESENT\": detect_pep_job_title(name)\n",
    "    }\n",
    "    return results_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Thresholds for flagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "THRESHOLDS_GT = {\n",
    "    \"NAME_COMPS\": 9,\n",
    "    \"NAME_CHARS\": 59,\n",
    "    \"SEP_COUNT\": 1,\n",
    "    \"NUM_REPEAT_NAME_COMPS\": 3,\n",
    "\n",
    "}\n",
    "\n",
    "THRESHOLDS_EQ = {\n",
    "    \"NAME_COMPS\": 1,\n",
    "}\n",
    "\n",
    "BOOL_FLAGS = {\n",
    "    \"HONORIFIC_PRESENT\": True,\n",
    "    \"JOB_TITLE_PRESENT\": True\n",
    "}\n",
    "\n",
    "thresholds = {\n",
    "    \"THRESHOLDS_GT\": THRESHOLDS_GT,\n",
    "    \"THRESHOLDS_EQ\": THRESHOLDS_EQ,\n",
    "    \"BOOL_FLAGS\": BOOL_FLAGS\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_name_flags(name_df: pd.DataFrame, thresholds: dict[dict[str, int]]) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Flags values in a pandas DataFrame based on given thresholds.\n",
    "\n",
    "    This function takes a pandas DataFrame `name_df` and a dictionary of thresholds `thresholds`,\n",
    "    and creates boolean flags in the DataFrame based on the specified thresholds. The flags are\n",
    "    created as additional columns in the DataFrame using the `.assign()` method, and the resulting\n",
    "    DataFrame with the flags is returned.\n",
    "\n",
    "    Args:\n",
    "        name_df (pd.DataFrame): The input DataFrame to be flagged.\n",
    "        thresholds (dict[dict[str, int]]): A dictionary of thresholds for flagging, with keys\n",
    "            \"THRESHOLDS_GT\" and \"THRESHOLDS_EQ\" for greater-than and equal-to checks, respectively.\n",
    "            The values are inner dictionaries with keys as column names in `name_df` and values\n",
    "            as threshold values for flagging.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: The input DataFrame `name_df` with additional columns for the flags created\n",
    "            based on the specified thresholds.\n",
    "\n",
    "    Example:\n",
    "            A  B  A_GT2_FLAG  B_EQ5_FLAG  TOTAL_FLAGS\n",
    "        0  1  4        False       False             0\n",
    "        1  2  5        False        True             1\n",
    "         2  3  6         True       False             1\n",
    "    \"\"\"\n",
    "    \n",
    "    flag_names = []\n",
    "    \n",
    "    # Greater-than checks\n",
    "    thresh = thresholds.get(\"THRESHOLDS_GT\", {})\n",
    "    for k,v in thresh.items():\n",
    "        flag_name = f\"{k.upper()}_GT{v}_FLAG\"\n",
    "        name_df = name_df.assign(**{flag_name: name_df[k] > v})\n",
    "        flag_names.append(flag_name)\n",
    "        if \"REPEAT_PHONETIC_COMPS\" in k:\n",
    "            phonetic_name_flag_name = flag_name\n",
    "        else:\n",
    "            phonetic_name_flag_name = False\n",
    "        \n",
    "    thresh = thresholds.get(\"THRESHOLDS_EQ\", {})\n",
    "    for k,v in thresh.items():\n",
    "        if v == 1 and not isinstance(v, bool):\n",
    "            flag_name = \"SINGLE_FLAG\"\n",
    "        else:\n",
    "            flag_name = f\"{k.upper()}_EQ{v}_FLAG\"\n",
    "            \n",
    "        name_df.loc[:, flag_name] = name_df.loc[:, k] == v\n",
    "        flag_names.append(flag_name)\n",
    "    \n",
    "    thresh = thresholds.get(\"BOOL_FLAGS\", {})\n",
    "    for k, v in thresh.items():\n",
    "        flag_name = f\"{k.upper()}_FLAG\"\n",
    "        name_df.loc[:, flag_name] = name_df.loc[:, k] == v\n",
    "        #name_df.loc[:, flag_name] = name_df.loc[:, k].astype(int)\n",
    "        flag_names.append(flag_name)\n",
    "\n",
    "    # Ignore CJK char names for SINGLE_FLAG col\n",
    "    cjk_names_flag = name_df.loc[:, \"name\"].map(detect_cjk_chars)\n",
    "    if \"SINGLE_FLAG\" in name_df.columns:\n",
    "        name_df.loc[:, \"SINGLE_FLAG\"] = name_df.loc[:, \"SINGLE_FLAG\"] *  ~cjk_names_flag\n",
    "    # Ignore phoneitc repeats in CJK char names\n",
    "    if phonetic_name_flag_name:\n",
    "        name_df.loc[:, phonetic_name_flag_name] = name_df.loc[:, phonetic_name_flag_name] *  ~cjk_names_flag\n",
    "\n",
    "\n",
    "    name_df.loc[:, flag_names] = name_df[flag_names].applymap(int)\n",
    "\n",
    "    name_df.loc[:, \"TOTAL_FLAGS\"] = name_df.loc[:, flag_names].sum(axis=1)\n",
    "    \n",
    "    return name_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "def execute_name_completeness(df):\n",
    "    name_fields = ['_source.data.names.name', '_source.data.names.name_type', '_source.data.names.primary_name']\n",
    "\n",
    "#Convert array to strings\n",
    "#    df['_source.data.names.primary_name'] = df['_source.data.names.primary_name'].apply(lambda x: ', '.join(map(str, x)))\n",
    "\n",
    "#Apply process_pep_name to each row and save as Series of dictionaries in Result\n",
    "    result = df['_source.data.names.primary_name'].apply(lambda x: process_pep_name(x))\n",
    "\n",
    "#Normalise the result to get df\n",
    "    result = pd.json_normalize(result)\n",
    "\n",
    "#Concatenate the results into df\n",
    "    df = pd.concat([df, result], axis=1)\n",
    "\n",
    "#Call the set_name_flags to flag issues with name column\n",
    "    df = set_name_flags(df, thresholds )\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\AlbinTouma\\AppData\\Local\\Temp\\ipykernel_17656\\758081539.py:67: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  name_df.loc[:, flag_names] = name_df[flag_names].applymap(int)\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    df = pd.read_parquet('../../parquet/DBPedia.parquet')\n",
    "    df = execute_name_completeness(df)\n",
    "    return df\n",
    "df = main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>NAME_COMPS_GT9_FLAG</th>\n",
       "      <th>NAME_CHARS_GT59_FLAG</th>\n",
       "      <th>SEP_COUNT_GT1_FLAG</th>\n",
       "      <th>NUM_REPEAT_NAME_COMPS_GT3_FLAG</th>\n",
       "      <th>SINGLE_FLAG</th>\n",
       "      <th>HONORIFIC_PRESENT_FLAG</th>\n",
       "      <th>JOB_TITLE_PRESENT_FLAG</th>\n",
       "      <th>TOTAL_FLAGS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>rd Baron Colwyn Anthony Hamilton-Smith</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Baron True Nicholas True</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>Baroness Mone Michelle Mone</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>282</th>\n",
       "      <td>Baron Wade of Chorlton William Wade</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>510</th>\n",
       "      <td>Baron Rooker Jeff Rooker</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186585</th>\n",
       "      <td>Baron Foster of Thames Bank Norman Foster</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186668</th>\n",
       "      <td>Baron Powell of Bayswater Charles Powell</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186695</th>\n",
       "      <td>rd Baron Lyell Charles Lyell</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188098</th>\n",
       "      <td>Lord Downpatrick Edward Windsor</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188293</th>\n",
       "      <td>Elisabeth Anne de Massy Baroness</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2100 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             name  NAME_COMPS_GT9_FLAG  \\\n",
       "3          rd Baron Colwyn Anthony Hamilton-Smith                    0   \n",
       "17                       Baron True Nicholas True                    0   \n",
       "139                   Baroness Mone Michelle Mone                    0   \n",
       "282           Baron Wade of Chorlton William Wade                    0   \n",
       "510                      Baron Rooker Jeff Rooker                    0   \n",
       "...                                           ...                  ...   \n",
       "186585  Baron Foster of Thames Bank Norman Foster                    0   \n",
       "186668   Baron Powell of Bayswater Charles Powell                    0   \n",
       "186695               rd Baron Lyell Charles Lyell                    0   \n",
       "188098            Lord Downpatrick Edward Windsor                    0   \n",
       "188293           Elisabeth Anne de Massy Baroness                    0   \n",
       "\n",
       "        NAME_CHARS_GT59_FLAG  SEP_COUNT_GT1_FLAG  \\\n",
       "3                          0                   0   \n",
       "17                         0                   0   \n",
       "139                        0                   0   \n",
       "282                        0                   0   \n",
       "510                        0                   0   \n",
       "...                      ...                 ...   \n",
       "186585                     0                   0   \n",
       "186668                     0                   0   \n",
       "186695                     0                   0   \n",
       "188098                     0                   0   \n",
       "188293                     0                   0   \n",
       "\n",
       "        NUM_REPEAT_NAME_COMPS_GT3_FLAG  SINGLE_FLAG  HONORIFIC_PRESENT_FLAG  \\\n",
       "3                                    0            0                       1   \n",
       "17                                   0            0                       1   \n",
       "139                                  0            0                       1   \n",
       "282                                  0            0                       1   \n",
       "510                                  0            0                       1   \n",
       "...                                ...          ...                     ...   \n",
       "186585                               0            0                       1   \n",
       "186668                               0            0                       1   \n",
       "186695                               0            0                       1   \n",
       "188098                               0            0                       1   \n",
       "188293                               0            0                       1   \n",
       "\n",
       "        JOB_TITLE_PRESENT_FLAG  TOTAL_FLAGS  \n",
       "3                            0            1  \n",
       "17                           0            1  \n",
       "139                          0            1  \n",
       "282                          0            1  \n",
       "510                          0            1  \n",
       "...                        ...          ...  \n",
       "186585                       0            1  \n",
       "186668                       0            1  \n",
       "186695                       0            1  \n",
       "188098                       0            1  \n",
       "188293                       0            1  \n",
       "\n",
       "[2100 rows x 9 columns]"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df[[ 'name', 'NAME_COMPS_GT9_FLAG', 'NAME_CHARS_GT59_FLAG', 'SEP_COUNT_GT1_FLAG',\n",
    "       'NUM_REPEAT_NAME_COMPS_GT3_FLAG', 'SINGLE_FLAG',\n",
    "       'HONORIFIC_PRESENT_FLAG', 'JOB_TITLE_PRESENT_FLAG', 'TOTAL_FLAGS',]]\n",
    "\n",
    "df[df['TOTAL_FLAGS'] >0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TOTAL_FLAGS</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>98.9</td>\n",
       "      <td>186244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.1</td>\n",
       "      <td>2056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             count   count\n",
       "TOTAL_FLAGS               \n",
       "0             98.9  186244\n",
       "1              1.1    2056\n",
       "2              0.0      43\n",
       "3              0.0       1"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "profiles = df.shape[0]\n",
    "count_flags = df['TOTAL_FLAGS'].value_counts()\n",
    "share_flags = count_flags.div(profiles).round(3) * 100\n",
    "pd.concat([share_flags, count_flags], axis=1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
